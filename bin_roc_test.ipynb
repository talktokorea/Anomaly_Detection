{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bin_roc_test.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMMAi9Zg3I1DR8IwHIGRTCt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/talktokorea/Anomaly_Detection/blob/main/bin_roc_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-3-EINkEx1d"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "qVOBp7sIE9gC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters for the synthetic data\n",
        "scale = 5\n",
        "size = 500"
      ],
      "metadata": {
        "id": "4lOuw9qAFADJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate class 1 out of a normal distribution\n",
        "class1_a = np.random.normal(loc = 10, scale = scale, size = size)\n",
        "class1_b = np.random.normal(loc = 1, scale = scale, size = size)"
      ],
      "metadata": {
        "id": "m8W7oAXDFBTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(class1_a)\n",
        "#print(class1_b)"
      ],
      "metadata": {
        "id": "EFWkPzWXte24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate class 2 out of a normal distribution\n",
        "class2_a = np.random.normal(loc = 1, scale = scale, size = size)\n",
        "class2_b = np.random.normal(loc = 5, scale = scale, size = size)"
      ],
      "metadata": {
        "id": "gnxfBdvrFFRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot both to show how much they intersect\n",
        "plt.figure(figsize=(5, 5))\n",
        "sns.scatterplot(x = class1_a, y = class1_b)\n",
        "sns.scatterplot(x = class2_a, y = class2_b)"
      ],
      "metadata": {
        "id": "cFTJmXoSFHf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_class1 = pd.DataFrame()\n",
        "df_class1['a'] = class1_a\n",
        "df_class1['b'] = class1_b\n",
        "df_class1['class'] = 0"
      ],
      "metadata": {
        "id": "4vJCxyfcFK7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_class2 = pd.DataFrame()\n",
        "df_class2['a'] = class2_a\n",
        "df_class2['b'] = class2_b\n",
        "df_class2['class'] = 1"
      ],
      "metadata": {
        "id": "Kd1CTnFxFNoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df_class1.append(df_class2, ignore_index = True)"
      ],
      "metadata": {
        "id": "JRx-O57wFP_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "oIAD50-kuQjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail()"
      ],
      "metadata": {
        "id": "XTRW49Diuj5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the dependent and independent variables\n",
        "X = df.drop(columns = ['class'])\n",
        "y = df['class']"
      ],
      "metadata": {
        "id": "OAwoUAklFQz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)"
      ],
      "metadata": {
        "id": "X6xGZKeoFUHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB"
      ],
      "metadata": {
        "id": "hvmdrRkeFWZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model object\n",
        "model = GaussianNB()"
      ],
      "metadata": {
        "id": "AYzzgXVxFYcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model to the training data\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "N23EaaZTFaDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the classes on the test data\n",
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "202Oa1XdFchi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the first 10 entries\n",
        "y_pred[:10]"
      ],
      "metadata": {
        "id": "CHYtXZiSFfXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the classes on the test data, and return the probabilities for each class\n",
        "y_proba = model.predict_proba(X_test)"
      ],
      "metadata": {
        "id": "bxVVZ_QuFgx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the first 10 entries\n",
        "y_proba[:10]"
      ],
      "metadata": {
        "id": "pujEi7plFjvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the predictions\n",
        "sns.scatterplot(x = X_test['a'], y = X_test['b'], hue = y_pred)"
      ],
      "metadata": {
        "id": "4ZD_kNoNFqgy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_aux = X_test.copy()"
      ],
      "metadata": {
        "id": "Pjp04eKDu9qv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_aux)"
      ],
      "metadata": {
        "id": "DRiLZ0WPvKFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test)"
      ],
      "metadata": {
        "id": "kLDNNKRJvQ4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_aux['class']=[1 if y==1 else 0 for y in y_test]"
      ],
      "metadata": {
        "id": "Q7c4I4YqvfYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_aux)"
      ],
      "metadata": {
        "id": "SPMgtJHxvrgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_aux['prob']=y_proba[:,1]   # cf. y_prob[:,0]\n",
        "#print(y_proba)"
      ],
      "metadata": {
        "id": "iL9hA1Uvvwd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(df_aux)"
      ],
      "metadata": {
        "id": "omYCXocIwHB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bins = [i/20 for i in range(20) ] + [1]\n",
        "sns.histplot(data=df_aux,x=\"prob\",hue=\"class\",bins=bins)"
      ],
      "metadata": {
        "id": "JZAFT3qP0UYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "06Kwdf0EFuTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_tpr_fpr(y_real, y_pred):\n",
        "    '''\n",
        "    Calculates the True Positive Rate (tpr) and the True Negative Rate (fpr) based on real and predicted observations\n",
        "    \n",
        "    Args:\n",
        "        y_real: The list or series with the real classes\n",
        "        y_pred: The list or series with the predicted classes\n",
        "        \n",
        "    Returns:\n",
        "        tpr: The True Positive Rate of the classifier\n",
        "        fpr: The False Positive Rate of the classifier\n",
        "    '''\n",
        "    \n",
        "    # Calculates the confusion matrix and recover each element\n",
        "    cm = confusion_matrix(y_real, y_pred)\n",
        "    TN = cm[0, 0]\n",
        "    FP = cm[0, 1]\n",
        "    FN = cm[1, 0]\n",
        "    TP = cm[1, 1]\n",
        "    \n",
        "    # Calculates tpr and fpr\n",
        "    tpr =  TP/(TP + FN) # sensitivity - true positive rate\n",
        "    fpr = 1 - TN/(TN+FP) # 1-specificity - false positive rate\n",
        "    \n",
        "    return tpr, fpr"
      ],
      "metadata": {
        "id": "DyqubIDNFxFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_n_roc_coordinates(y_real, y_proba, resolution = 50):\n",
        "    '''\n",
        "    Calculates \"n\" ROC Curve coordinates (tpr and fpr) by manipulating the threshold used to predict the class.\n",
        "    \n",
        "    Args:\n",
        "        y_real: The list or series with the real classes.\n",
        "        y_proba: The array with the probabilities for each class, obtained by using the `.predict_proba()` method.\n",
        "        resolution: Defines how many divisions the threshold will have, and how many coordinates will be calculated (default = 50).\n",
        "        \n",
        "    Returns:\n",
        "        tpr_list: The list of TPRs representing each threshold.\n",
        "        fpr_list: The list of FPRs representing each threshold.\n",
        "    '''\n",
        "    tpr_list = [0]\n",
        "    fpr_list = [0]\n",
        "    for i in range(resolution):\n",
        "        threshold = i/resolution\n",
        "        y_pred = y_proba[:, 1] > threshold\n",
        "        tpr, fpr = calculate_tpr_fpr(y_real, y_pred)\n",
        "        tpr_list.append(tpr)\n",
        "        fpr_list.append(fpr)\n",
        "    return tpr_list, fpr_list"
      ],
      "metadata": {
        "id": "UfkgotXOFz3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_roc_curve(tpr, fpr, scatter = True):\n",
        "    '''\n",
        "    Plots the ROC Curve by using the list of coordinates (tpr and fpr).\n",
        "    \n",
        "    Args:\n",
        "        tpr: The list of TPRs representing each coordinate.\n",
        "        fpr: The list of FPRs representing each coordinate.\n",
        "        scatter: When True, the points used on the calculation will be plotted with the line (default = True).\n",
        "    '''\n",
        "    plt.figure(figsize = (5, 5))\n",
        "    if scatter:\n",
        "        sns.scatterplot(x = fpr, y = tpr)\n",
        "    sns.lineplot(x = fpr, y = tpr)\n",
        "    sns.lineplot(x = [0, 1], y = [0, 1], color = 'green')\n",
        "    plt.xlim(-0.05, 1.05)\n",
        "    plt.ylim(-0.05, 1.05)\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Positive Rate\")"
      ],
      "metadata": {
        "id": "xxgASdDtF2A5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculates 10 coordinates of the ROC Curve\n",
        "tpr, fpr = get_n_roc_coordinates(y_test, y_proba, resolution = 10)"
      ],
      "metadata": {
        "id": "yGHvR_fiF3Gx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plots the ROC curve\n",
        "plot_roc_curve(tpr, fpr)"
      ],
      "metadata": {
        "id": "-0zPy7RzF69B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_all_roc_coordinates(y_real, y_proba):\n",
        "    '''\n",
        "    Calculates all the ROC Curve coordinates (tpr and fpr) by considering each point as a treshold for the predicion of the class.\n",
        "    \n",
        "    Args:\n",
        "        y_real: The list or series with the real classes.\n",
        "        y_proba: The array with the probabilities for each class, obtained by using the `.predict_proba()` method.\n",
        "        \n",
        "    Returns:\n",
        "        tpr_list: The list of TPRs representing each threshold.\n",
        "        fpr_list: The list of FPRs representing each threshold.\n",
        "    '''\n",
        "    tpr_list = [0]\n",
        "    fpr_list = [0]\n",
        "    for i in range(len(y_proba)):\n",
        "        threshold = y_proba[i, 1]\n",
        "        y_pred = y_proba[:, 1] >= threshold\n",
        "        tpr, fpr = calculate_tpr_fpr(y_real, y_pred)\n",
        "        tpr_list.append(tpr)\n",
        "        fpr_list.append(fpr)\n",
        "    return tpr_list, fpr_list"
      ],
      "metadata": {
        "id": "-hdTOEoTF8bq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculates ALL coordinates of the ROC Curve\n",
        "tpr, fpr = get_all_roc_coordinates(y_test, y_proba)"
      ],
      "metadata": {
        "id": "C4ITBlVUF_ah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plots the ROC curve\n",
        "plot_roc_curve(tpr, fpr, scatter = False)"
      ],
      "metadata": {
        "id": "jDLcewkgGBZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import RocCurveDisplay"
      ],
      "metadata": {
        "id": "bd7f1tPDGEcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_sklearn_roc_curve(y_real, y_pred):\n",
        "    '''\n",
        "    Plots the ROC Curve with the sklearn methods by using the real observations and their predictions.\n",
        "    \n",
        "    Args:\n",
        "        y_real: The list or series with the real classes\n",
        "        y_pred: The list or series with the predicted classes\n",
        "    '''\n",
        "    fpr, tpr, _ = roc_curve(y_real, y_pred)\n",
        "    roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr).plot()\n",
        "    roc_display.figure_.set_size_inches(5,5)"
      ],
      "metadata": {
        "id": "doDgeHeeGHVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plots the ROC curve using the sklearn methods\n",
        "plot_sklearn_roc_curve(y_test, y_proba[:, 1])"
      ],
      "metadata": {
        "id": "YS9w4VzEGKeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score"
      ],
      "metadata": {
        "id": "nQ3pLrcHGO2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_classifier(y_real, y_pred):\n",
        "    '''\n",
        "    Prints the accuracy, precision, recall and roc auc scores for the classifier.\n",
        "    \n",
        "    Args:\n",
        "        y_real: The list or series with the real classes\n",
        "        y_pred: The list or series with the predicted classes\n",
        "    '''\n",
        "    print(f\"Accuracy: {accuracy_score(y_real, y_pred):.4f}\")\n",
        "    print(f\"Precision: {precision_score(y_real, y_pred):.4f}\")\n",
        "    print(f\"Recall: {recall_score(y_real, y_pred):.4f}\")\n",
        "    print(f\"ROC AUC: {roc_auc_score(y_real, y_pred):.4f}\")"
      ],
      "metadata": {
        "id": "JOwzDB1VGRNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_classifier(y_test, y_pred)"
      ],
      "metadata": {
        "id": "TKTNv0B6GTPa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}